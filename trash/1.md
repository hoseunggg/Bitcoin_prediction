---
marp: true
theme: default
paginate: true
mermaid: true
size: 16:9
style: |
    section {
        position: relative;
        padding-top: 60px;

        display: flex;
        flex-direction: column;
        align-items: flex-start;
        justify-content: flex-start;
        text-align: left;

        font-size: 22px;  /* 본문 기본 글자 크기 축소 */
    }

    section.title {
      background-color: #f9f9f9;
      color: #333;
      text-align: center;
      justify-content: center;
      align-items: center;
    }    

    /* 상단 텍스트 + 하단 선 */
    section::before {
        content: "SungKunKwan University";
        position: absolute;
        top: 20px;
        left: 60px;
        font-size: 16px;  /* 이전 20px → 16px */
        color: #888;
        width: calc(100% - 120px);
        padding-bottom: 12px;
        border-bottom: 1px solid #ccc;
    }

    section::after {
        content: "Finance Lab";
        position: absolute;
        bottom: 10px;
        right: 60px;
        font-size: 16px;  /* 이전 20px → 16px */
        color: #888;
        width: calc(100% - 120px);
        border-top: 1px solid #ccc;
        text-align: right;
        display: block;
    }

    /* 제목 크기 축소 */
    h1 {
        padding-top: 100px;
        font-size: 48px;  /* 이전 36px */
    }
    h2 {
        padding-top: 10px;
        font-size: 36px;  /* 이전 28px */
        margin-bottom: 8px;
        text-align: left;
    }
    h3 {
        font-size: 24px;  /* 이전 22px */
        text-align: left;
    }

    /* 표 크기 축소 */
    table {
        font-size: 9px;  /* 이전 18px */
        text-align: left;
    }

---

# Finance Lab

## Hoseung

1. Factors Influencing Bitcoin return

---

## 1. Factors Influencing Bitcoin Volatility

Previous studies aimed to analyze the factors that influence Bitcoin volatility.  

However, due to the unique characteristics of Bitcoin, using monthly volatility may reduce accuracy.  

As a result, shifting the analysis to a daily frequency was suggested as more meaningful.

### Emerging Issues

- When using daily data, the number of available variables is significantly reduced.  
- Low frequency of usable data makes it difficult to assign meaningful economic interpretation.

---

## 2. Research Contribution


### Limitations of Existing Linear Models
Most studies assume linearity, but Bitcoin’s high volatility and nonlinearity challenge this assumption.

### Comparison: Linear vs. Nonlinear Models
Nonlinear models (e.g., Random Forest, XGBoost) outperform linear ones when using only past price data.

### Impact of Exogenous Variables
Adding macroeconomic variables improves nonlinear models significantly, while linear models show limited gains suggesting nonlinear relationships.

### Identification of Key Variables
Currently analyzing 17 macroeconomic indicators. Plan to identify and compare variable importance across both model types.




---

#### 2. Dataset ( daily )

| Variable     | Mean      | Std     | Skewness | Kurtosis | ADF Statistic | p-value | Formula                                                                                     |
|--------------|-----------|---------|----------|----------|---------------|---------|---------------------------------------------------------------------------------------------|
| PriceUSD     | 0.0022    | 0.0406  | -0.1060  | 6.2599   | -32.8852      | 0.0000  | $\Delta PriceUSD_t = \frac{PriceUSD_t - PriceUSD_{t-1}}{PriceUSD_{t-1}}$              |
| BkCount      | 147.8582  | 16.5530 | -0.3723  | 1.1361   | -6.4035       | 0.0000  | $BkCount_t$                                                                                 |
| BkSize       | 0.0101    | 0.1437  | 1.1260   | 4.2925   | -6.6801       | 0.0000  | $\Delta BkSize_t = \frac{BkSize_t - BkSize_{t-1}}{BkSize_{t-1}}$                              |
| DiffM        | 0.0023    | 0.0171  | 1.1096   | 42.8772  | -7.9966       | 0.0000  | $\Delta DiffM_t = \frac{DiffM_t - DiffM_{t-1}}{DiffM_{t-1}}$                                 |
| FeeUSD       | 3.8228    | 6.6907  | 4.0090   | 20.2875  | -3.3593       | 0.0124  | $FeeUSD_t$                                                                                  |
| Hash_Rate    | 0.0097    | 0.1261  | 0.7776   | 2.5203   | -26.0803      | 0.0000  | $\Delta Hash\_Rate_t = \frac{Hash\_Rate_t - Hash\_Rate_{t-1}}{Hash\_Rate_{t-1}}$               |
| RevUSD       | 0.0090    | 0.1294  | 0.8198   | 2.8512   | -37.6867      | 0.0000  | $\Delta RevUSD_t = \frac{RevUSD_t - RevUSD_{t-1}}{RevUSD_{t-1}}$                              |
| TxValAdjUSD  | 0.0660    | 0.4274  | 2.8765   | 17.7569  | -6.8575       | 0.0000  | $\Delta TxValAdjUSD_t = \frac{TxValAdjUSD_t - TxValAdjUSD_{t-1}}{TxValAdjUSD_{t-1}}$           |
| URTH         | 0.0003    | 0.0099  | -0.9888  | 24.6577  | -9.4896       | 0.0000  | $\Delta URTH_t = \frac{URTH_t - URTH_{t-1}}{URTH_{t-1}}$                                     |
| GSPC         | 0.0003    | 0.0105  | -0.6172  | 21.9839  | -9.7565       | 0.0000  | $\Delta GSPC_t = \frac{GSPC_t - GSPC_{t-1}}{GSPC_{t-1}}$                                     |
| RiskFree     | 0.0019    | 0.0275  | 1.9750   | 27.2993  | -6.2836       | 0.0000  | $\Delta RiskFree_t = RiskFree_t - RiskFree_{t-1}$                                            |
| OAS          | 4.1297    | 1.0263  | 2.5562   | 8.7330   | -3.4424       | 0.0096  | $OAS_t$                                                                                     |
| TenYear      | 0.0006    | 0.0286  | 1.6946   | 44.9141  | -8.0629       | 0.0000  | $\Delta TenYear_t = \frac{TenYear_t - TenYear_{t-1}}{TenYear_{t-1}}$                         |
| TwoYear      | 0.0017    | 0.0472  | 0.9434   | 13.1693  | -24.9820      | 0.0000  | $\Delta TwoYear_t = \frac{TwoYear_t - TwoYear_{t-1}}{TwoYear_{t-1}}$                         ||
| VIX          | 19.5261   | 8.4034  | 2.0822   | 8.4596   | -4.1856       | 0.0007  | $VIX_t$                                                                                     |
| USDIndex     | 0.0000    | 0.0026  | 0.2479   | 5.3907   | -10.5806      | 0.0000  | $\Delta USDIndex_t = \frac{USDIndex_t - USDIndex_{t-1}}{USDIndex_{t-1}}$                      |
| ExpInflation | 0.0003    | 0.0198  | 5.7912   | 210.3612 | -12.2697      | 0.0000  | $\Delta ExpInflation_t = \frac{ExpInflation_t - ExpInflation_{t-1}}{ExpInflation_{t-1}}$      |
| USNewsSent   | -0.0432   | 0.2005  | -0.8955  | 1.1627   | -2.8680       | 0.0492  | $USNewsSent_t$                                                                              |

---
## 1. AR  & AR-X Models

- **Autoregression Model**  
  This is the baseline model that predicts volatility using past values of realized volatility:  
  $$
  RV_{t+1} = \alpha_0 + \sum_{i=1}^{6} \alpha_i RV_{t+1-i} + \varepsilon_{t+1}
  $$

- **AR-X Model**  
  This model extends the AR model by including exogenous predictors $X_{i,t}$, such as macroeconomic and on-chain variables:  
  $$
  RV_{t+1} = \alpha_0 + \sum_{i=1}^{6} \alpha_i RV_{t+1-i} + \sum_{i=1}^{N} \beta_i X_{i,t} + \varepsilon_{t+1}
  $$

---

## 2. Machine Learning (Random Foreset, XGBoosting, LightGBM)

### Random Forest (RF)

- An ensemble of multiple decision trees  
- Each tree is trained on a randomly sampled dataset (bootstrap sample)

Let $T^{(b)}(X)$ be the prediction from the $b$-th decision tree trained on a bootstrap sample.  
Then, the random forest prediction is:

$$
\hat{y} = \frac{1}{B} \sum_{b=1}^{B} T^{(b)}(X)
$$

---

### Splitting Criterion (Regression Trees)

Each decision tree finds the best split at each node by minimizing the Mean Squared Error (MSE):

$$
\text{MSE}_{\text{split}} = \frac{1}{n_L} \sum_{i \in L} (y_i - \bar{y}_L)^2 + \frac{1}{n_R} \sum_{i \in R} (y_i - \bar{y}_R)^2
$$

Where:  
- $L, R$: left and right child nodes  
- $n_L, n_R$: number of samples in each node  
- $\bar{y}_L, \bar{y}_R$: average target values in each node  

---

## XGBoost (Extreme Gradient Boosting)

- Builds trees sequentially to reduce errors  
- Utilizes gradient descent to minimize loss  

---

### Residuals in XGBoost

XGBoost updates predictions by sequentially fitting trees to residuals.

At iteration $t$, the residual for the $i$-th sample is:

$$
r_i^{(t)} = -\frac{\partial \ell(y_i, \hat{y}_i^{(t-1)})}{\partial \hat{y}_i^{(t-1)}}
$$

The next tree $f_t(x)$ is trained to predict $r_i^{(t)}$.

Predictions are updated as:

$$
\hat{y}_i^{(t)} = \hat{y}_i^{(t-1)} + \eta \cdot f_t(x_i)
$$


### Example : Squared Error Loss

If the loss function is $\ell(y, \hat{y}) = \frac{1}{2}(y - \hat{y})^2$, then the residual simplifies to $r_i^{(t)} = y_i - \hat{y}_i^{(t-1)}$

---


---


---